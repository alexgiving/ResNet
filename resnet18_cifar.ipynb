{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd7KnHWrIKH-"
      },
      "source": [
        "# ResNet18 for CIFAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tIzDJucIJm3",
        "outputId": "a18b3d75-a5ab-473d-84b2-e8ca68249029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Using cached torch-1.13.0-cp310-none-macosx_11_0_arm64.whl (55.7 MB)\n",
            "Collecting typing-extensions\n",
            "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions, torch\n",
            "Successfully installed torch-1.13.0 typing-extensions-4.4.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.14.0-cp310-cp310-macosx_11_0_arm64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in ./base/lib/python3.10/site-packages (from torchvision) (1.13.0)\n",
            "Collecting requests\n",
            "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: typing-extensions in ./base/lib/python3.10/site-packages (from torchvision) (4.4.0)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.23.4-cp310-cp310-macosx_11_0_arm64.whl (13.3 MB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Using cached Pillow-9.3.0-cp310-cp310-macosx_11_0_arm64.whl (2.9 MB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting charset-normalizer<3,>=2\n",
            "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Installing collected packages: urllib3, pillow, numpy, idna, charset-normalizer, certifi, requests, torchvision\n",
            "Successfully installed certifi-2022.9.24 charset-normalizer-2.1.1 idna-3.4 numpy-1.23.4 pillow-9.3.0 requests-2.28.1 torchvision-0.14.0 urllib3-1.26.12\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6RxYn0MOc1h"
      },
      "source": [
        "# RESNET18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nAQFUhVXOelv"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1BBtjnMDPMzh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GrJSyEOpQer6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DCdaVdEMQqHs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Th32m4FQs0p",
        "outputId": "c4429309-129f-4252-9ecc-bd925549e9a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "num_epochs = 4\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "model = ResNet18(num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001, momentum = 0.9)  \n",
        "\n",
        "# CIFAR10 dataset \n",
        "train_loader, valid_loader = data_loader(data_dir='./data',\n",
        "                                         batch_size=batch_size)\n",
        "\n",
        "test_loader = data_loader(data_dir='./data',\n",
        "                              batch_size=batch_size,\n",
        "                              test=True)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxT3TpCgUSKb"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Jk2BlDYOQvQk",
        "outputId": "5b60c8c4-3c03-48b7-a539-886d12f17cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step [1/1407], Loss: 2.4941\n",
            "Step [101/1407], Loss: 2.3909\n",
            "Step [201/1407], Loss: 1.5298\n",
            "Step [301/1407], Loss: 1.6803\n",
            "Step [401/1407], Loss: 1.7067\n",
            "Step [501/1407], Loss: 1.5459\n",
            "Step [601/1407], Loss: 1.5878\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d132e32faf7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             print('Step [{}/{}], Loss: {:.4f}' \n\u001b[1;32m     22\u001b[0m                    .format(id_step+1, total_step, loss.item()))\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     print ('Epoch [{}/{}], Loss: {:.4f}' \n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import gc\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for id_step, (images, labels) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        del images, labels, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        if id_step % 100 == 0: \n",
        "            print('Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(id_step+1, total_step, loss.item()))\n",
        "        gc.collect()\n",
        "\n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, loss.item()))\n",
        "            \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valid_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "    \n",
        "        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvk4cciOYUJj",
        "outputId": "4b2f68e8-87c3-42dc-a683-29cab18a589d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = \"drive/MyDrive/ColabNotebooks/resnet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjcaAM5eQzGp"
      },
      "outputs": [],
      "source": [
        "PATH = f'{path}/cifar_net.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h-ABSiZ18VVD"
      },
      "outputs": [],
      "source": [
        "m2 = ResNet18(PATH)\n",
        "\n",
        "model = m2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ__BnkQRMX8",
        "outputId": "150ab843-06eb-4d87-da61-ba16411b25f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 69.21 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        del images, labels, outputs\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boVvkz1kTkMi"
      },
      "outputs": [],
      "source": [
        "model_pretrained = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_pretrained.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "num_ftrs = model_pretrained.fc.in_features\n",
        "model_pretrained.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "model_pretrained = model_pretrained.to(device)\n",
        "\n",
        "optimizer_conv = torch.optim.SGD(model_pretrained.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)\n",
        "\n",
        "                         "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.8 ('base': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "1eb8b73d0db0711ac8de61bec2cf8be707fb5bfc7e3148b96912f8951796624b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
